{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f5b23d-d9f6-4f12-a7e0-983686f888f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T19:00:22.188286Z",
     "iopub.status.busy": "2023-12-12T19:00:22.187984Z",
     "iopub.status.idle": "2023-12-12T19:00:22.192878Z",
     "shell.execute_reply": "2023-12-12T19:00:22.192124Z",
     "shell.execute_reply.started": "2023-12-12T19:00:22.188261Z"
    }
   },
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\"> \n",
    "<br>\n",
    "<b> (Little demo) Accessibility utilities </b> <br>\n",
    "Contact author(s): Andrés A. Plazas Malagón <br>\n",
    "Last verified to run: 2024-08-01 <br>\n",
    "LSST Science Pipelines version: Weekly 2024_16 <br>\n",
    "Container Size: small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac73400-1c64-43e7-a116-3d92cdce5af2",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook will demonstrate:\n",
    "\n",
    "- the use of functions to calculate color contrast to check the [Web Content Accessibility Guidelines (WCAG)](https://www.w3.org/WAI/standards-guidelines/wcag/) international standard,\n",
    "- the use of the software [`Glasbey`](https://github.com/lmcinnes/glasbey) to find color-blind friendly palettes,\n",
    "- the use of the software [`DaltonLens`](https://github.com/DaltonLens/DaltonLens-Python/tree/master) to simulate color vision deficiencies (e.g., deuteranomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eef134-2a78-49d1-a361-f2ad64c8f368",
   "metadata": {},
   "source": [
    "### 1.1 Package Imports\n",
    "\n",
    "`Glasbey` and `DaltonLens` can be installed in the Rubin Science Platform by opening a new terminal and using `pip`:\n",
    "\n",
    "- `python3 -m pip install --user daltonlens`\n",
    "- `python3 -m pip install --user glasbey`\n",
    "\n",
    "The [Python Image Library](https://omz-software.com/pythonista/docs/ios/PIL.html), PIL, is used to read a PNG image to be used by `DaltonLens`.\n",
    "The [seaborn](https://seaborn.pydata.org/) package is used to display the `glasbey` color palettes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfc9f1-27c9-404c-9dcd-8a99a2013b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import numpy as np\n",
    "from daltonlens import convert, simulate, generate\n",
    "import matplotlib.pyplot as plt\n",
    "import glasbey\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33359ddc-28f7-48c0-bb59-6bcea675caa3",
   "metadata": {},
   "source": [
    "### 1.2 Define Functions and Parameters\n",
    "\n",
    "The functions `luminance`, `contrast_ratio`, `hex_to_rgb`, and `check_contrast` can be used to calculate the relative contrast between two colors and compare them with the Web Content Accessibility Guidelines. These guidelines are detailed in the official WCAG documentation, which can be found here: [Web Content Accessibility Guidelines (WCAG) 2.1](https://www.w3.org/TR/WCAG21/#contrast-minimum)\n",
    "\n",
    "These calculations are also performed by websites such as the [WebAIM Contrast Checker](https://webaim.org/resources/contrastchecker/). \n",
    "\n",
    "The function `display_color_vision_simulations` displays an original image and simulated versions for different types of color vision deficiencies using the `DaltonLens` software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087da399-7063-4d2f-83d5-9ed729d75621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**_Function_**: `luminance` \n",
    "\n",
    "Calculate the relative luminance of a color based on its RGB values.\n",
    "\n",
    "The formula for calculating the relative luminance (L) of a color is:\n",
    "\n",
    "$L = 0.2126 \\times R + 0.7152 \\times G + 0.0722 \\times B$\n",
    "\n",
    "Where:\n",
    "- $R$, $G$, and $B$ are the linearized values of the red, green, and blue components of the color, respectively.\n",
    "\n",
    "The linearization process involves converting the sRGB values (which are in the range 0-255) to a linear scale:\n",
    "- For sRGB values $\\leq 0.03928$, linearized $R, G, B = \\frac{\\text{sRGB}}{12.92}$\n",
    "- For sRGB values $> 0.03928$, linearized $R, G, B = \\left(\\frac{\\text{sRGB} + 0.055}{1.055}\\right)^{2.4}$\n",
    "\n",
    "Reference: [relative luminance](https://www.w3.org/TR/WCAG21/#dfn-relative-luminance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8609d3-8e19-4078-9975-01926e777ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def luminance(r, g, b):\n",
    "    \"\"\"\n",
    "    Calculate the relative luminance of a color based on its RGB values.\n",
    "\n",
    "    The function converts the RGB values to a luminance value according to\n",
    "    the formula specified by the WCAG guidelines, which accounts for the\n",
    "    human eye's sensitivity to different colors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r : int\n",
    "        The red component of the color, in the range 0-255.\n",
    "    g : int\n",
    "        The green component of the color, in the range 0-255.\n",
    "    b : int\n",
    "        The blue component of the color, in the range 0-255.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The relative luminance of the color.\n",
    "    \"\"\"\n",
    "    a = [r, g, b]\n",
    "    for i in range(3):\n",
    "        a[i] = a[i] / 255.0\n",
    "        a[i] = a[i] / 12.92 if a[i] <= 0.03928 else ((a[i] + 0.055) / 1.055) ** 2.4\n",
    "    return a[0] * 0.2126 + a[1] * 0.7152 + a[2] * 0.0722"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf22de-2c3d-449a-a00b-6d3c331e6e78",
   "metadata": {},
   "source": [
    "**_Function_**: `contrast_ratio`\n",
    "\n",
    "Compute the contrast ratio between two colors based on their luminance values.\n",
    "\n",
    "The contrast ratio between two colors is calculated as:\n",
    "\n",
    "$\\text{Contrast Ratio} = \\frac{L1 + 0.05}{L2 + 0.05}$\n",
    "\n",
    "Where:\n",
    "- $L1$ and $L2$ are the relative luminance values of the two colors.\n",
    "- $L1$ is the luminance of the lighter color.\n",
    "- $L2$ is the luminance of the darker color.\n",
    "\n",
    "Reference: [contrast ratio](https://www.w3.org/TR/WCAG21/#dfn-contrast-ratio).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de64684-772b-4d39-ae17-b8a99fd35b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_ratio(color1, color2):\n",
    "    \"\"\"\n",
    "    Calculate the contrast ratio between two colors.\n",
    "\n",
    "    The contrast ratio is computed based on the luminance values of the two colors,\n",
    "    following the WCAG guidelines. It is used to determine the readability of text\n",
    "    or the visibility of UI components against background colors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    color1 : tuple\n",
    "        A tuple representing the RGB values of the first color.\n",
    "    color2 : tuple\n",
    "        A tuple representing the RGB values of the second color.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The contrast ratio between the two colors.\n",
    "    \"\"\"\n",
    "    l1 = luminance(*color1)\n",
    "    l2 = luminance(*color2)\n",
    "    if l1 > l2:\n",
    "        return (l1 + 0.05) / (l2 + 0.05)\n",
    "    else:\n",
    "        return (l2 + 0.05) / (l1 + 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881ff26-a13a-4513-b679-3f500c8da20e",
   "metadata": {},
   "source": [
    "**_Function_**: `hex_to_rgb`\n",
    "\n",
    "Convert hexadecimal color codes to RGB tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f917e4b-4c09-4b0c-ab0f-86e9158bf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(hex_color):\n",
    "    \"\"\"\n",
    "    Convert a hexadecimal color code to an RGB tuple.\n",
    "\n",
    "    This function takes a hexadecimal color string and converts it into a\n",
    "    tuple of integers representing the red, green, and blue components of the color.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hex_color : str\n",
    "        A string representing the hexadecimal color code, e.g., '#RRGGBB'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple of three integers (R, G, B) representing the color in RGB format.\n",
    "    \"\"\"\n",
    "    hex_color = hex_color.lstrip('#')\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967799a-1037-4d25-ae4f-55ad0de5201d",
   "metadata": {},
   "source": [
    "**_Function_**: `check_contrast`\n",
    "\n",
    "Evaluate the contrast ratio against WCAG guidelines for different text and UI component sizes.\n",
    "\n",
    "The Web Content Accessibility Guidelines (WCAG) 2.1 provide the following standards for contrast ratios:\n",
    "\n",
    "- **Normal Text (AA)**: A contrast ratio of at least 4.5:1.\n",
    "- **Large Text (AA)**: A contrast ratio of at least 3:1.\n",
    "- **Graphics and User Interface Components (AA)**: A contrast ratio of at least 3:1.\n",
    "- **Normal Text (AAA)**: A contrast ratio of at least 7:1.\n",
    "- **Large Text (AAA)**: A contrast ratio of at least 4.5:1.\n",
    "\n",
    "Reference: [WCGA 2.1 standards](https://www.w3.org/TR/WCAG21/#contrast-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e358d0-eee0-489d-aede-2e2a2e271e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contrast(ratio):\n",
    "    \"\"\"\n",
    "    Evaluate the contrast ratio against WCAG guidelines for different text and UI component sizes.\n",
    "\n",
    "    The function checks whether the given contrast ratio meets the WCAG requirements\n",
    "    for normal text, large text, and graphical UI components under different compliance levels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratio : float\n",
    "        The contrast ratio to evaluate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the results for different WCAG criteria, indicating 'Pass' or 'Fail'.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"Normal Text AA\": ratio >= 4.5,\n",
    "        \"Large Text AA\": ratio >= 3,\n",
    "        \"Graphics/UI Components AA\": ratio >= 3,\n",
    "        \"Normal Text AAA\": ratio >= 7,\n",
    "        \"Large Text AAA\": ratio >= 4.5\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7063bbe-92a3-4f16-b1b9-18f2cee94608",
   "metadata": {},
   "source": [
    "**_Function_**: `display_color_vision_simulations`\n",
    "\n",
    "Use `DaltonLens` to display an original image and simulated versions for different types of color vision deficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301467ff-daa0-4b24-8d72-f87526679f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_color_vision_simulations(image, simulator, color_anomalies):\n",
    "    \"\"\"\n",
    "    Display the original image and simulated versions for different types of color vision deficiencies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: `np.array`\n",
    "        The original image to be displayed.\n",
    "\n",
    "    simulator: `DaltonLens` obejct\n",
    "        `DaltonLens` simulator.\n",
    "\n",
    "    color_anomalies: `list`\n",
    "        List of color vision anomalies.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "    for idx, (title, deficiency) in enumerate(color_anomalies):\n",
    "        ax = axs[idx // 2, idx % 2]\n",
    "        \n",
    "        if deficiency is None:\n",
    "            # Show the original image\n",
    "            display_im = image\n",
    "        else:\n",
    "            # Apply the simulator to the input image to simulate the color anomaly\n",
    "            display_im = simulator.simulate_cvd(image, deficiency, severity=1.0)\n",
    "        \n",
    "        ax.imshow(display_im)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')  # Hide the axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc76be1-3aa7-4ec8-b062-43396093144f",
   "metadata": {},
   "source": [
    "## 2 Color contrast calculation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620af212-c99e-49a9-bcd4-9bc12c75dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = \"#3D7555\"\n",
    "color2 = \"#0400FB\"\n",
    "rgb1 = hex_to_rgb(color1)\n",
    "rgb2 = hex_to_rgb(color2)\n",
    "\n",
    "ratio = contrast_ratio(rgb1, rgb2)\n",
    "results = check_contrast(ratio)\n",
    "\n",
    "print(f\"The contrast ratio between {color1} and {color2} is: {ratio:.2f}\")\n",
    "print(\"Pass/Fail Criteria:\")\n",
    "for criteria, passed in results.items():\n",
    "    print(f\"{criteria}: {'Pass' if passed else 'Fail'}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ddd0d-365e-4fae-973c-482ff0eb52bc",
   "metadata": {},
   "source": [
    "## 3. Demonstration of the `glasbey` software\n",
    "\n",
    "The `glasbey` library enables the creation of color palettes optimized for categorical data, based on techniques from the paper [\"Colour Displays for Categorical Images\" by Glasbey, Heijden, Toh, and Gray](https://onlinelibrary.wiley.com/doi/abs/10.1002/col.20327). This library also provides features designed to make these palettes more distinguishable for individuals with various degrees of color vision deficiency.\n",
    "\n",
    "Reference: [Glasbey color-blind safe palettes](https://glasbey.readthedocs.io/en/latest/color_vision_deficiency.html)\n",
    "\n",
    "The following example follows the `glasbey` [documentation](https://glasbey.readthedocs.io/en/latest/color_vision_deficiency.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e74b1-2cd9-429d-b707-1b92b9aa394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "palette_glasbey = glasbey.create_palette(palette_size=12, colorblind_safe=True, cvd_severity=100)\n",
    "sns.palplot(palette_glasbey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976590c4-4738-4446-8885-5d939317860f",
   "metadata": {},
   "source": [
    "## 4. Demonstration of the `DaltonLens` Software\n",
    "\n",
    "There are several open-source simulators for color deficiencies, but some of them are inaccurate.  The following website does a good comparison between them:\n",
    "\n",
    "- [Review of Open Source Color Blindness Simulations](https://daltonlens.org/opensource-cvd-simulation/)\n",
    "\n",
    "The authors provide the software `DaltonLens` that uses more accurate models: \n",
    "\n",
    "- [DaltonLens repository](https://github.com/DaltonLens/DaltonLens-Python/tree/master)\n",
    "- [Understanding the color-vision deficiency simulator implemented in `DaltonLens`](https://daltonlens.org/understanding-cvd-simulation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b0ec6-a13b-4ca7-8619-2fce1ab0bd8a",
   "metadata": {},
   "source": [
    "Define the simulator: `Simulator_AutoSelect()` automatically selects the most suitable algorithm based on the type of color vision deficiency and its severity. For tritan simulations, it uses the model by [Brettel, Viénot, and Molon (1997)](https://pubmed.ncbi.nlm.nih.gov/9316278/). For protanomaly and deuteranomaly with severity levels less than 1, the [Machado, Oliveira, and Fernandes (2009)](https://pubmed.ncbi.nlm.nih.gov/19834201/) model is chosen. For complete protanopia and deuteranopia (severity level equal to 1), the [Viénot, Brettel, and Mollon (1999)](https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1520-6378(199908)24:4%3C243::AID-COL5%3E3.0.CO;2-3) model is utilized. This selection process ensures the use of the most accurate simulation technique for the specified conditions.\n",
    "\n",
    "More details can be found in the file `simulate.py` from the `DaltonLens` code:\n",
    "\n",
    "**Machado 2009**:  \n",
    "A model proposed by Machado, Oliveira, and Fernandes (2009) in their paper *\"A physiologically-based model for simulation of color vision deficiency\"*. This model is similar to Brettel1997 for simulating dichromacy and uses it as a reference to scale parameters. It is capable of simulating various severity levels by shifting the peak wavelength for a specific cone, which is considered a more robust method than simply interpolating with the original image. However, it is noted that this model does not perform well for tritanopia.\n",
    "\n",
    "**Brettel & Molon, 1997**:  \n",
    "An algorithm developed by Brettel, Viénot, and Mollon (1997) detailed in the paper *\"Computerized simulation of color appearance for dichromats\"*. This model is somewhat more complex than the one by Viénot & Brettel & Mollon (1999) but is particularly effective for simulating tritanopia. It is considered one of the most reliable references in the literature for this purpose.\n",
    "\n",
    "**Vienot, 1999**:  \n",
    "An algorithm described by Viénot, Brettel, and Mollon (1999) in their study *\"Digital video colourmaps for checking the legibility of displays by dichromats.\"* This model is recommended for simulating protanopia and deuteranopia, although it is not accurate for tritanopia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337d869-b03c-405d-9e21-05042a7fef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = simulate.Simulator_AutoSelect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb242d14-4198-45d8-9b75-650b5f8109f3",
   "metadata": {},
   "source": [
    "Define the color deficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d4420-7fd9-4c23-bd3e-732cb461f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_anomalies = [\n",
    "    (\"Original\", None), \n",
    "    (\"Protanomaly\", simulate.Deficiency.PROTAN), \n",
    "    (\"Deuteranomaly\", simulate.Deficiency.DEUTAN), \n",
    "    (\"Tritanomaly\", simulate.Deficiency.TRITAN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66aeed9-dd20-4ea0-9066-5e2cb872150b",
   "metadata": {},
   "source": [
    "Read an image from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba95225-845e-43d5-8b0e-d60380386383",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./figures/ucd-lc-portal-screenshot.png\"\n",
    "im1 = np.asarray(PIL.Image.open(file).convert('RGB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93bea0-76f8-4c22-be65-72aee005dc0f",
   "metadata": {},
   "source": [
    "Create the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9f2fa-6e08-410b-ba68-c139a1211a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_color_vision_simulations(im1, simulator, color_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36488ea6-25d4-4a38-9176-b84eb90ef854",
   "metadata": {},
   "source": [
    "Read another image, consisting of light curves from DP0.2 tutorial `DP02_07b_Variable_Star_Lightcurves`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03e729-b7cf-4dbb-a432-de921aaa097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./figures/light_curves_dalton_lens_demo.png\"\n",
    "im2 = np.asarray(PIL.Image.open(file).convert('RGB'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826a738-7ea0-46cf-8bc6-c60676542959",
   "metadata": {},
   "source": [
    "Create the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806d06f-fc3f-4b7a-ad8d-7af247834bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_color_vision_simulations(im2, simulator, color_anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
